# Analyse textuelle

## Introduction

- Un des [**domaines de recherche les plus actifs**]{.orange} en _data science_
- [**Beaucoup d'applications**]{.orange} potentielles pour la statistique publique :
    - Donn√©es d'[**enqu√™te**]{.blue2}
    - Donn√©es [**administratives**]{.blue2}
    - Donn√©es [**priv√©es**]{.blue2} mobilisables pour la statistique publique
- Traitement automatique : fait r√©f√©rence √† des t√¢ches [**vari√©es**]{.orange}

## Encoder du texte

- Id√©e de l'[**encodding**]{.orange} :
    - Transformer une information de tr√®s haute dimension (√©minemment complexe)...
    - ... en information √† dimension plus limit√©e...
    - ... qui peut √™tre exploit√©e par un ordinateur !

## Premi√®re approche : Bag of Words

- Id√©e : texte = ensemble de mots que l'on pioche plus ou moins fr√©quemment

- Outil classique et imm√©diat : la [**matrice document-terme**]{.blue2}.

- Regardons sur un exemple, sur le corpus suivant : 
    - _"La pratique du tricot et du crochet"_
    - _"Transmettre la passion du timbre"_
    - _"Vivre de sa passion"_


## Exemple de "document-terme"{.smaller}


<div style="overflow-x: auto; width: 100%;">
  <table style="border-collapse: collapse; width: 100%; text-align: center;">
    <thead>
      <tr>
        <th></th>
        <th>La pratique du tricot et du crochet</th>
        <th>Transmettre la passion du timbre</th>
        <th>Vivre de sa passion</th>
      </tr>
    </thead>
    <tbody>
      <tr><td>crochet</td><td>1/7</td><td>0</td><td>0</td></tr>
      <tr><td>de</td><td>0</td><td>0</td><td>1/4</td></tr>
      <tr><td>du</td><td>2/7</td><td>1/5</td><td>0</td></tr>
      <tr><td>et</td><td>1/7</td><td>0</td><td>0</td></tr>
      <tr><td>la</td><td>1/7</td><td>1/5</td><td>0</td></tr>
      <tr><td>passion</td><td>0</td><td>1/5</td><td>1/4</td></tr>
      <tr><td>pratique</td><td>1/7</td><td>0</td><td>0</td></tr>
      <tr><td>sa</td><td>0</td><td>0</td><td>1/4</td></tr>
      <tr><td>timbre</td><td>0</td><td>1/5</td><td>0</td></tr>
      <tr><td>transmettre</td><td>0</td><td>1/5</td><td>0</td></tr>
      <tr><td>tricot</td><td>1/7</td><td>0</td><td>0</td></tr>
      <tr><td>vivre</td><td>0</td><td>0</td><td>1/4</td></tr>
    </tbody>
  </table>
</div>


## Le TF-IDF {.smaller}

[TF-IDF]{.orange} (_Term Frequency ‚Äì Inverse Document Frequency_) : 
  
  - Quantifie l'importance d'un mot dans un document, relativement √† un ensemble de documents (le corpus).
  - Usage ancien en NLP (moteurs de recherche, analyses de similarit√©s, etc.)


[L‚Äôid√©e est simple]{.blue} :

  - Un mot est important dans un document s‚Äôil :
    - appara√Æt souvent dans ce document (TF),
    - mais rarement dans l‚Äôensemble des documents (IDF).

- Forme tr√®s simple d'[**apprentissage**]{.blue2}
- Mais repr√©sentation [**sparse**]{.blue2}, fl√©au de la dimension

## Exemple de TF-IDF{.scrollable}

<div style="overflow-x: auto; width: 100%;">
  <table style="border-collapse: collapse; width: 100%; text-align: center;">
    <thead>
      <tr>
        <th></th>
        <th>La pratique du tricot et du crochet</th>
        <th>Transmettre la passion du timbre</th>
        <th>Vivre de sa passion</th>
      </tr>
    </thead>
    <tbody>
      <tr><td>crochet</td><td>0.157</td><td>0</td><td>0</td></tr>
      <tr><td>de</td><td>0</td><td>0</td><td>0.275</td></tr>
      <tr><td>du</td><td>0.116</td><td>0.081</td><td>0</td></tr>
      <tr><td>et</td><td>0.157</td><td>0</td><td>0</td></tr>
      <tr><td>la</td><td>0.058</td><td>0.081</td><td>0</td></tr>
      <tr><td>passion</td><td>0</td><td>0.081</td><td>0.101</td></tr>
      <tr><td>pratique</td><td>0.157</td><td>0</td><td>0</td></tr>
      <tr><td>sa</td><td>0</td><td>0</td><td>0.275</td></tr>
      <tr><td>timbre</td><td>0</td><td>0.220</td><td>0</td></tr>
      <tr><td>transmettre</td><td>0</td><td>0.220</td><td>0</td></tr>
      <tr><td>tricot</td><td>0.157</td><td>0</td><td>0</td></tr>
      <tr><td>vivre</td><td>0</td><td>0</td><td>0.275</td></tr>
    </tbody>
  </table>
</div>


## Les embeddings W2V {.nostretch}

- _Text embeddings_ : [**repr√©sentation dense**]{.orange} qui capture les grandes structures d'un corpus.
- Projection du corpus dans le meilleur espace vectoriel possible pour rapprocher les termes s√©mantiquement proches. 
- Exemple de [**word2vec**]{.orange} (2013), apprentissage d'embeddings √† l'aide d'une t√¢che de pr√©diction des mots √† partir de leur contexte

![](https://minio.lab.sspcloud.fr/lgaliana/generative-art/pythonds/w2v_vecto.png){width="70%" fig-align="center"}

## Les embeddings W2V

![](img/word_embedding.png)


## Les transformers {.nostretch}

- ¬´ [*Attention Is All You Need*](https://arxiv.org/abs/1706.03762) ¬ª
- Aujourd'hui, les meilleurs mod√®les de langage reposent sur une m√™me architecture de r√©seaux de neurone : le [**Transformer**]{.orange}
- Embeddings des mots qui composent un texte deviennent [**contextuels**]{.orange}
- Explosion des mod√®les de langage [**g√©n√©ratifs**]{.orange}

## Applications pour la statistique publique

- Classification dans des [**nomenclatures**]{.orange} :
    - [**Profession**]{.blue2} (enqu√™tes, recensement de la population)
    - [**Activit√©**]{.blue2} des entreprises
    - [**Produits**]{.blue2} de consommation
- [**Appariements**]{.orange}
- [**Extraction automatique**]{.orange} de contenu au sein de documents textuels
- Mod√®les de langage [**g√©n√©ratifs**]{.orange} : assistants de code, RAG, etc.

## Application 2

- Consignes sur [le site web](https://inseefrlab.github.io/cours-nouvelles-donnees-site/applications/ape.html)
- Codification automatique des entreprises dans la nomenclature d'activit√©s
- Exploitation des donn√©es Sirene avec {{< fa brands python >}} et `TorchTextClassifiers` (m√©thode Fasttext)
- Ouverture √† la probl√©matique du MLOps appliqu√©e au NLP

- ‚úçüèª [**Lien vers le TD**](https://inseefrlab.github.io/cours-nouvelles-donnees-site/applications/ape.html) 

## Application 2 (optionnelle)

- Consignes sur [le site web](https://inseefrlab.github.io/cours-nouvelles-donnees-site/textes_exemples.html)
- Appariements flous entre noms de produits de supermarch√©s
- Exploitation `OpenFoodFacts` avec `Elasticsearch` et {{< fa brands python >}}

<a href="https://datalab.sspcloud.fr/launcher/ide/jupyter-python?autoLaunch=true&amp;onyxia.friendlyName=%C2%ABpython-datascience%C2%BB&amp;init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&amp;init.personalInitArgs=%C2%ABmodern-ds%20elastic_intro%C2%BB&amp;security.allowlist.enabled=false" target="_blank" rel="noopener"><img src="https://img.shields.io/badge/SSPcloud-Tester%20via%20SSP--cloud-informational&amp;color=yellow?logo=Python" alt="Onyxia"></a>